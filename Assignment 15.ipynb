{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08c41247-67cb-47ac-8a61-5c7f9da4c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 1 ) Artificial Intelligence :  Smart Application that can perform its own task without human intervension eg : Self driving car 2) Robots 3) Alexa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711d0c6f-af35-4d44-8173-033461012c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 1 ) Machine Learning : It Provides stat tool to analyze, visualize, predictive Models and Forecasting Eg: 1) Amazon and Netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "108f8a8e-a273-4f19-b77c-2c1431b788da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 1 )Deep Learning: It Minic the Human Brain : Eg : Image Rcognition , Chat Box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab1b78f-9d9d-4f53-8254-138efcf56512",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 2 ) supervised Learning : It is has two features 1) Classification and 2) Dataset 1) Classification : It Output is categorical here you known the output which is dependent on \n",
    "## input parameters eg : No of hours Student Study & NO of Hours student have O/P will be Pass or Fail\n",
    "## 2) Regression : output features is continous like : Size of House and No of room it will effect the price of House."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be564089-c98f-4907-bac9-46e0ca01d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 3 ) unsupervised Learning : It is Clusters Group  mean Group of similar data eg: Customer Segmennt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f820f5-3296-4b52-99d3-98fc39c03c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 4 )1 )  Artificial intelligence (AI) is a vast field that focuses on building intelligent computers that can carry out tasks that would ordinarily need human intelligence, like making decisions, understanding spoken language, and perceiving objects. Machine learning and deep learning are just two of the many approaches used in artificial intelligence (AI).\n",
    "##2) Ml :To help the computer system recognise patterns and make predictions, this procedure employs statistical models.\n",
    "##3) DL: Artificial neural networks are used in DL (Deep Learning), a branch of machine learning, to learn from massive volumes of data. These networks can learn and recognise patterns in data because they are built to resemble the structure and operation of the human brain. For tasks involving the comprehension of audio, pictures, and natural language, DL is especially helpful.\n",
    "## 4) DS : In order to extract knowledge and insights from data, the interdisciplinary area of data science (DS) combines methods from computer science, statistics, mathematics, and domain-specific knowledge. Data collection, cleansing, transformation, analysis, visualisation, and interpretation are all included in this process. Data scientists create predictive models and take data-driven decisions using techniques from statistics and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e8ea2ad-3249-4fb6-a3ca-bb165939dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 5) Supervised : Supervised learning uses labeled data to learn a function that maps input variables to the output variable, \n",
    "## while unsupervised learning uses unlabeled data to learn the underlying structure or patterns in the data. \n",
    "## Semi - supervised learning :is a combination of both techniques and uses partially labeled data to improve the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bdec529-b5e9-4c10-9d77-9a2f43496193",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 6) Training Set: The training set is the subset of the data used to train the model. It is the largest subset \n",
    "##of the data and is used to optimize the model parameters by adjusting the weights and biases in the model. \n",
    "##The model is trained on this set until it converges and achieves the desired accuracy.\n",
    "\n",
    "## Validation Set: The validation set is the subset of the data used to evaluate the performance of the model during training. \n",
    "##It is used to tune the hyperparameters of the model, such as the learning rate, regularization, and number of hidden layers. \n",
    "##The validation set is used to prevent overfitting, which occurs when the model performs well on the training set but poorly on new, \n",
    "##unseen data. By evaluating the model on a separate validation set, we can avoid overfitting and select the best model.\n",
    "\n",
    "##Test Set: The test set is the subset of the data used to evaluate the final performance of the model. It is used to estimate\n",
    "##the performance of the model on new, unseen data that was not used in training or validation. \n",
    "##The test set is only used once after the model has been fully trained and validated. \n",
    "##The performance on the test set gives an estimate of how well the model will perform on new, real-world data.\n",
    "\n",
    "##The importance of each term is as follows:\n",
    "\n",
    "##Training Set: The training set is important because it is used to train the model and optimize its parameters. \n",
    "##The more data we have in the training set, the better the model can learn the underlying patterns in the data.\n",
    "\n",
    "##Validation Set: The validation set is important because it is used to select the best model and prevent overfitting. \n",
    "##By evaluating the model on a separate validation set, we can select the best model and avoid overfitting, \n",
    "##which can lead to poor performance on new, unseen data.\n",
    "\n",
    "##Test Set: The test set is important because it provides an estimate of the model's performance on new, unseen data. \n",
    "##By evaluating the model on a separate test set, we can estimate how well the model will perform in the real world, \n",
    "##where the data is not known in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1186bc-de65-41a8-8cbf-6175ddd9c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 7) Unsupervised learning is a useful technique for anomaly detection because it can identify patterns or structures in the data \n",
    "##without prior knowledge of the classes or labels of the data. Anomalies or outliers are data points that do not conform to the \n",
    "##expected patterns or structures, and they can be identified as deviations from the normal behavior of the data.\n",
    "\n",
    "##There are several unsupervised learning techniques that can be used for anomaly detection, including:\n",
    "\n",
    "##Clustering: Clustering is a technique used to group similar data points together based on their proximity in the feature space. \n",
    "##Anomalies can be identified as data points that do not belong to any of the clusters or are far from the cluster centers.\n",
    "\n",
    "##Dimensionality reduction: Dimensionality reduction is a technique used to reduce the number of features or variables in the\n",
    "##data while preserving the most important information. Anomalies can be identified as data points that cannot be accurately \n",
    "##reconstructed from the reduced feature space.\n",
    "\n",
    "##Density estimation: Density estimation is a technique used to estimate the probability density function of the data. \n",
    "##Anomalies can be identified as data points with low probability densities or are far from the high-density regions.\n",
    "\n",
    "##Neural networks: Neural networks can also be used for unsupervised anomaly detection by training the network to reconstruct \n",
    "##the input data. Anomalies can be identified as data points that are difficult to reconstruct or have high reconstruction errors.\n",
    "\n",
    "##The main advantage of unsupervised learning for anomaly detection is that it does not require labeled data or prior \n",
    "##knowledge of the anomalies. It can automatically detect anomalies and adapt to changing patterns in the data. \n",
    "##However, the downside of unsupervised learning is that it may also detect normal variations in the data as anomalies, \n",
    "##leading to false positives. Therefore, careful selection and tuning of the unsupervised learning techniques are essential \n",
    "##for effective anomaly detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b6c6b6-8b42-4002-b1eb-4730605366d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ans 8 ) Here are some commonly used supervised learning algorithms:\n",
    "\n",
    "#Linear regression\n",
    "##Logistic regression\n",
    "##Decision trees\n",
    "##Random forests\n",
    "##Gradient Boosting\n",
    "##Support Vector Machines (SVM)\n",
    "##Naive Bayes classifiers\n",
    "##Neural networks (including deep learning)\n",
    "\n",
    "##Here are some commonly used unsupervised learning algorithms:\n",
    "\n",
    "##K-Means clustering\n",
    "##Hierarchical clustering\n",
    "##Principal Component Analysis (PCA)\n",
    "##t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
    "##Autoencoders\n",
    "##Generative Adversarial Networks (GAN)\n",
    "##Density-Based Spatial Clustering of Applications with Noise (DBSCAN)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
